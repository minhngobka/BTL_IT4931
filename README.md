# ğŸš€ BÃ i táº­p lá»›n: PhÃ¢n tÃ­ch HÃ nh trÃ¬nh KhÃ¡ch hÃ ng (Customer Journey)

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng Big Data theo kiáº¿n trÃºc Kappa Ä‘á»ƒ phÃ¢n tÃ­ch hÃ nh vi ngÆ°á»i dÃ¹ng trÃªn má»™t trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ (view, cart, purchase) theo thá»i gian thá»±c.

## ğŸ› ï¸ YÃªu cáº§u cÃ i Ä‘áº·t (Prerequisites)

TrÆ°á»›c khi báº¯t Ä‘áº§u, báº¡n cáº§n cÃ i Ä‘áº·t cÃ¡c cÃ´ng cá»¥ sau trÃªn mÃ¡y Ubuntu:

1.  **Git:** `sudo apt install git`
2.  **Docker:** [Link hÆ°á»›ng dáº«n cÃ i Docker](https://docs.docker.com/engine/install/ubuntu/)
3.  **Python 3.10+ & Venv:** `sudo apt install python3.10-venv`
4.  **Minikube:** [Link hÆ°á»›ng dáº«n cÃ i Minikube](https://minikube.sigs.k8s.io/docs/start/)
5.  **Kubectl:** `sudo snap install kubectl --classic`
6.  **Helm:** `sudo snap install helm --classic`

## ğŸ“¦ CÃ i Ä‘áº·t dá»± Ã¡n

### 1. Clone Repository

```bash
git clone https://github.com/DucTham2004/bigdata-customer-journey.git
cd bigdata_project
```

### 2. Thiáº¿t láº­p MÃ´i trÆ°á»ng Python

```bash
# Táº¡o mÃ´i trÆ°á»ng áº£o
python3 -m venv venv

# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng
source venv/bin/activate

# CÃ i Ä‘áº·t thÆ° viá»‡n (náº¿u cÃ³ file requirements.txt)
# (Báº¡n cÃ³ thá»ƒ táº¡o file nÃ y báº±ng lá»‡nh: pip freeze > requirements.txt)
pip install pandas kafka-python
```

### 3. Táº£i Dá»¯ liá»‡u (Ráº¥t quan trá»ng)

Do file dá»¯ liá»‡u quÃ¡ lá»›n, nÃ³ khÃ´ng Ä‘Æ°á»£c lÆ°u trÃªn GitHub. Báº¡n cáº§n tá»± táº£i file `2019-Oct.csv` tá»« link Kaggle dÆ°á»›i Ä‘Ã¢y:

* **Link Kaggle:** [https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store](https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store)

Sau khi táº£i vá», hÃ£y **Ä‘áº·t file `2019-Oct.csv` vÃ o thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n** (ngang hÃ ng vá»›i file `simulator.py`).

## ğŸš€ Khá»Ÿi cháº¡y Háº¡ táº§ng (Giai Ä‘oáº¡n 1)

CÃ¡c lá»‡nh nÃ y chá»‰ cáº§n cháº¡y 1 láº§n Ä‘á»ƒ thiáº¿t láº­p mÃ´i trÆ°á»ng Kubernetes.

### 1. Khá»Ÿi Ä‘á»™ng Minikube

```bash
minikube start --driver=docker --cpus=4 --memory=8g
```

### 2. CÃ i Ä‘áº·t MongoDB

```bash
helm repo add bitnami [https://charts.bitnami.com/bitnami](https://charts.bitnami.com/bitnami)
helm install my-mongo bitnami/mongodb --set auth.enabled=false
```

### 3. CÃ i Ä‘áº·t Strimzi (Kafka Operator)

```bash
helm repo add strimzi [https://strimzi.io/charts/](https://strimzi.io/charts/)
helm install strimzi-operator strimzi/strimzi-kafka-operator
```

### 4. Äá»£i cÃ¡c Operator cháº¡y

DÃ¹ng VSCode má»Ÿ má»™t Terminal má»›i (Ctrl + Shift + \`) vÃ  cháº¡y:
```bash
kubectl get pods -w
```
Äá»£i cho Ä‘áº¿n khi cáº£ `my-mongo-mongodb-...` vÃ  `strimzi-cluster-operator-...` Ä‘á»u `Running`.

### 5. Táº¡o Kafka Cluster (KRaft)

Sau khi operator Ä‘Ã£ cháº¡y, hÃ£y Ã¡p dá»¥ng file cáº¥u hÃ¬nh Kafka cá»§a chÃºng ta:
```bash
kubectl apply -f kafka-combined.yaml
```
Tiáº¿p tá»¥c theo dÃµi `kubectl get pods -w`. Äá»£i cho Ä‘áº¿n khi cÃ¡c pod `my-cluster-kafka-0` vÃ  `my-cluster-entity-operator-...` cÅ©ng `Running`.

---

## ğŸƒ Cháº¡y MÃ´ phá»ng (Data Simulator)

Sau khi toÃ n bá»™ háº¡ táº§ng Ä‘Ã£ `Running`:

### 1. TÃ¬m Ä‘á»‹a chá»‰ Kafka

```bash
# Láº¥y IP cá»§a Minikube
minikube ip

# Láº¥y Cá»•ng (Port) cá»§a Kafka
kubectl get service my-cluster-kafka-external-bootstrap -o=jsonpath='{.spec.ports[0].nodePort}'
```

### 2. Cáº­p nháº­t file `simulator.py`

Má»Ÿ file `simulator.py` vÃ  cáº­p nháº­t dÃ²ng `KAFKA_BROKER` báº±ng IP vÃ  Cá»•ng báº¡n vá»«a tÃ¬m Ä‘Æ°á»£c:

```python
# VÃ­ dá»¥:
KAFKA_BROKER = '192.168.49.2:31234'
```

### 3. Cháº¡y script

(Äáº£m báº£o báº¡n váº«n Ä‘ang trong mÃ´i trÆ°á»ng `venv`)
```bash
python simulator.py
```
Báº¡n sáº½ tháº¥y script báº¯t Ä‘áº§u gá»­i dá»¯ liá»‡u lÃªn Kafka.