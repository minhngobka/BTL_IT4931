# Big Data Customer Journey Analytics

Real-time e-commerce customer journey analytics system using Apache Spark, Kafka, and MongoDB.

## About This Project

This project demonstrates a **real-time big data analytics pipeline** for analyzing customer behavior in an e-commerce platform. It processes millions of events (views, carts, purchases) in real-time to generate insights about customer journeys, conversion funnels, and behavior patterns.

**Key Features:**
- âš¡ **Real-time streaming** with Apache Spark Structured Streaming
- ğŸ“Š **Complex aggregations** (windowed, stateful, sessionization)
- ğŸ”— **Stream-static joins** with product catalogs
- ğŸ¤– **Machine Learning** (K-Means clustering, Random Forest classification)
- ğŸ¯ **Exactly-once semantics** with checkpointing
- ğŸ“ˆ **Analytics dashboard** via MongoDB queries

## Architecture

```
CSV Data (5.3GB) â†’ Kafka â†’ Spark Streaming â†’ MongoDB
                              â†“
                      Batch ML Jobs (6 hours)
```
## Setup
```
# Setup Docker
docker-compose up --build

# Download dataset (5.3GB)
# Get 2019-Oct.csv from: https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store
# Place it in: data/raw/2019_Oct.csv

```
## Usage
```
# Äáº©y data vÃ o Kafka sá»­ dá»¥ng \kafka\producers\csv_producer.py
python3 csv_producer.py
# Hiá»ƒn thá»‹ data producer gá»­i vÃ o Kafka 
docker exec -it kafka kafka-console-consumer --bootstrap-server kafka:9092 --topic user_behavior_events --from-beginning

# Äáº©y data tá»« Kafka vÃ o Spark
docker exec -it spark-app python src/main.py

# Kiá»ƒm tra logs:
# Kiá»ƒm tra Spark Master
docker logs spark-master

# Kiá»ƒm tra Spark Worker
docker logs spark-worker

# Kiá»ƒm tra Kafka
docker logs kafka

# Kiá»ƒm tra Spark App
docker logs -f spark-app
```
Truy cáº­p Web UI:
Spark Master: http://localhost:8080
Spark Worker: http://localhost:8081
