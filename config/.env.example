# ============================================
# Big Data Project Environment Variables
# ============================================
# Copy this file to .env and customize for your environment
# Run: minikube ip to get MINIKUBE_IP
# Run: kubectl get svc my-cluster-kafka-external-bootstrap to get KAFKA port

# --- KAFKA Configuration ---
# For Minikube external access: <MINIKUBE_IP>:<NODEPORT>
# Example: 192.168.49.2:31927
KAFKA_EXTERNAL_BROKER=192.168.49.2:31927

# For in-cluster access (inside K8s pods)
KAFKA_INTERNAL_BROKER=my-cluster-kafka-bootstrap.default.svc.cluster.local:9092

# Kafka topic name
KAFKA_TOPIC=customer_events

# --- MongoDB Configuration ---
# For in-cluster access (inside K8s pods)
MONGODB_HOST=my-mongo-mongodb.default.svc.cluster.local
MONGODB_PORT=27017

# For local port-forward: localhost:27017
# MONGODB_HOST=localhost
# MONGODB_PORT=27017

MONGODB_DATABASE=bigdata_db
MONGODB_URI=mongodb://my-mongo-mongodb.default.svc.cluster.local:27017/

# --- Event Simulator Settings ---
# Path to input CSV file
CSV_FILE_PATH=data/raw/ecommerce_events_2019_oct.csv

# Rows per batch when reading CSV
CHUNK_SIZE=1000

# Sleep time between messages (seconds) - simulates real-time
SLEEP_TIME=0.01

# --- Spark Configuration ---
# Checkpoint directory for streaming applications
SPARK_CHECKPOINT_DIR=/opt/spark/work-dir/checkpoints

# Spark log level (WARN, INFO, DEBUG)
SPARK_LOG_LEVEL=WARN

# --- Development / Minikube ---
# Minikube IP address (used for external Kafka connection)
MINIKUBE_IP=192.168.49.2
